{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQgOFZXg4gGyJcOJT0Acez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAHIL9581/research/blob/main/Informal_to_Formal_Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 1: Install Libraries\n",
        "print(\"⏳ Installing required libraries...\")\n",
        "!pip install -q transformers sentencepiece\n",
        "print(\"✅ Installation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rOBfHjmXres",
        "outputId": "42afe21d-52f6-41d1-dbe1-f8447442f964"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Installing required libraries...\n",
            "✅ Installation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 2 (Corrected): Load an Alternative Model\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Check if a GPU is available and set the device accordingly.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# CHANGE: Using a new, publicly available model for grammar/formality.\n",
        "model_name = \"vennify/t5-base-grammar-correction\"\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "print(f\"⏳ Loading model '{model_name}'...\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "print(f\"✅ Model loaded successfully on {str(device).upper()}!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU51oya-Xrg9",
        "outputId": "41267268-d9fe-40f6-c1ec-3f7f8cb5daa4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ Loading model 'vennify/t5-base-grammar-correction'...\n",
            "✅ Model loaded successfully on CPU!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 3 (Corrected): Define Inference Function with a New Prefix\n",
        "def convert_to_formal(informal_text):\n",
        "    # Use a prefix suitable for the new model\n",
        "    input_text = f\"grammar: {informal_text}\"\n",
        "\n",
        "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=256, truncation=True).to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        max_length=256,\n",
        "        num_beams=5,\n",
        "        early_stopping=True\n",
        "    )\n",
        "    formal_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return formal_text\n",
        "\n",
        "print(\"✅ Style transfer function updated for the new model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hieMzYZXrjW",
        "outputId": "83ad02e0-72d3-4adb-ba10-e8b6d64a6b54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Style transfer function updated for the new model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 4: Test with Sample Data\n",
        "print(\"PERFORMING TESTS ON SAMPLE DATA\".center(40, \"=\"))\n",
        "\n",
        "sample_dataset = [\n",
        "    \"omg, that movie was so cool!\",\n",
        "    \"i dunno what to do, gotta finish my hw.\",\n",
        "    \"Hey, wanna hang out later?\",\n",
        "    \"That concert was totally awesome, the band rocked.\",\n",
        "    \"He's kinda late, hope he's ok.\",\n",
        "    \"sry, can't make it tonight.\",\n",
        "]\n",
        "\n",
        "for sentence in sample_dataset:\n",
        "    formal_version = convert_to_formal(sentence)\n",
        "    print(f\"\\n💬 Informal: {sentence}\")\n",
        "    print(f\"✅ Formal  : {formal_version}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoQ8zKpRXrm8",
        "outputId": "064d617c-bad5-44bb-e34f-36f84205a898"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====PERFORMING TESTS ON SAMPLE DATA=====\n",
            "\n",
            "💬 Informal: omg, that movie was so cool!\n",
            "✅ Formal  : OMG, that movie was so cool!\n",
            "\n",
            "💬 Informal: i dunno what to do, gotta finish my hw.\n",
            "✅ Formal  : I don't know what to do, gotta finish my homework.\n",
            "\n",
            "💬 Informal: Hey, wanna hang out later?\n",
            "✅ Formal  : Hey, wanna hang out later?\n",
            "\n",
            "💬 Informal: That concert was totally awesome, the band rocked.\n",
            "✅ Formal  : That concert was totally awesome, the band rocked.\n",
            "\n",
            "💬 Informal: He's kinda late, hope he's ok.\n",
            "✅ Formal  : He's kind of late, hope he's ok.\n",
            "\n",
            "💬 Informal: sry, can't make it tonight.\n",
            "✅ Formal  : Sorry, can't make it tonight.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Block 5: Interactive Demo\n",
        "print(\"\\nINTERACTIVE DEMO: TRY YOUR OWN TEXT\".center(40, \"=\"))\n",
        "print(\"Enter an informal sentence below, or type 'quit' to exit.\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        user_input = input(\"\\n> Enter your text: \")\n",
        "        if user_input.lower() == 'quit':\n",
        "            print(\"👋 Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Generate and print the formal version\n",
        "        formal_output = convert_to_formal(user_input)\n",
        "        print(f\"Formal version: {formal_output}\")\n",
        "\n",
        "    except (KeyboardInterrupt, EOFError):\n",
        "        print(\"\\n👋 Goodbye!\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPfS3lj9X2ts",
        "outputId": "a27c5441-72ce-444b-c98c-cd39cd99f54e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==\n",
            "INTERACTIVE DEMO: TRY YOUR OWN TEXT==\n",
            "Enter an informal sentence below, or type 'quit' to exit.\n",
            "\n",
            "> Enter your text: r u going to the party l8r?\n",
            "Formal version: r u going to the party?\n",
            "\n",
            "> Enter your text: wanna grab some food? im starving.\n",
            "Formal version: Wanna grab some food? im starving.\n",
            "\n",
            "> Enter your text: btw, that new movie was sick!\n",
            "Formal version: btw, that new movie was sick!\n",
            "\n",
            "> Enter your text: quit\n",
            "👋 Goodbye!\n"
          ]
        }
      ]
    }
  ]
}